[使用LLaMa-Factory简单高效微调大模型](https://zhuanlan.zhihu.com/p/689333581)
[ollama 使用自己的微调模型](https://blog.csdn.net/spiderwower/article/details/138755776)
[解决LLama Factory微调并量化大模型时cuda/pytorch/python/auto-gptq/vllm/的冲突的详细说明](https://www.5bei.cn/detailed-instructions-for-resolving-conflicts-betw.html)
[LlamaFactory Lora 合并大模型,GGUF 转换与 Ollama 部署Open_WebUI全流程](https://blog.csdn.net/weixin_42745482/article/details/145323102)


20250307